@article{https://doi.org/10.1049/el.2019.4202,
author = {Elbir, A. and Aydin, N.},
title = {Music genre classification and music recommendation by using deep learning},
journal = {Electronics Letters},
volume = {56},
number = {12},
pages = {627-629},
keywords = {learning (artificial intelligence), feature extraction, neural nets, music, recommender systems, pattern classification, music genre classification system, music recommendation, deep learning, music listening applications, music acoustic characteristics, deep neural network model, acoustic features extraction},
doi = {https://doi.org/10.1049/el.2019.4202},
url = {https://ietresearch.onlinelibrary.wiley.com/doi/abs/10.1049/el.2019.4202},
eprint = {https://ietresearch.onlinelibrary.wiley.com/doi/pdf/10.1049/el.2019.4202},
abstract = {Today, music is a very important and perhaps inseparable part of people's daily life. There are many genres of music and these genres are different from each other, resulting in people to have different preferences of music. As a result, it is an important and up-to-date issue to classify music and to recommend people new music in music listening applications and platforms. Classifying music by their genre is one of the most useful techniques used to solve this problem. There are a number of approaches for music classification and recommendation. One approach is based on the acoustic characteristics of music. In this study, a music genre classification system and music recommendation engine, which focuses on extracting representative features that have been obtained by a novel deep neural network model, have been proposed. Acoustic features extracted from these networks have been utilised for music genre classification and music recommendation on a data set.},
year = {2020}
}

@misc{defferrard2017fma,
      title={FMA: A Dataset For Music Analysis}, 
      author={Michaël Defferrard and Kirell Benzi and Pierre Vandergheynst and Xavier Bresson},
      year={2017},
      eprint={1612.01840},
      archivePrefix={arXiv},
      primaryClass={cs.SD}
}

@inbook{Benson_2007, 
	place={Cambridge}, 
	title={Chapter 1: Waves and Harmonics}, 
	booktitle={Music: A mathematical offering}, 
	publisher={Cambridge University Press}, 
	author={Benson, D. J.},
	 year={2007}, 
	pages={1–15}
}

@misc{Team, title={How to structure a pop song}, url={https://www.aimm.edu/blog/how-to-structure-a-pop-song}, journal={College for Best Online Music Programs and Degrees AIMM.edu}, author={Team, AIMM}}

@misc{Crossley-Holland, 
	title={Rhythm}, 
	url={https://www.britannica.com/art/rhythm-music}, 
	journal={Encyclopædia Britannica}, 
	publisher={Encyclopædia Britannica, inc.}, 
	author={Crossley-Holland, Peter}
}

@article{SAHIDULLAH2012543,
title = {Design, analysis and experimental evaluation of block based transformation in MFCC computation for speaker recognition},
journal = {Speech Communication},
volume = {54},
number = {4},
pages = {543-565},
year = {2012},
issn = {0167-6393},
doi = {https://doi.org/10.1016/j.specom.2011.11.004},
url = {https://www.sciencedirect.com/science/article/pii/S0167639311001622},
author = {Md. Sahidullah and Goutam Saha},
keywords = {Speaker recognition, MFCC, DCT, Correlation matrix, Decorrelation technique, Linear transformation, Block transform, Narrow-band noise, Missing feature theory},
abstract = {Standard Mel frequency cepstrum coefficient (MFCC) computation technique utilizes discrete cosine transform (DCT) for decorrelating log energies of filter bank output. The use of DCT is reasonable here as the covariance matrix of Mel filter bank log energy (MFLE) can be compared with that of highly correlated Markov-I process. This full-band based MFCC computation technique where each of the filter bank output has contribution to all coefficients, has two main disadvantages. First, the covariance matrix of the log energies does not exactly follow Markov-I property. Second, full-band based MFCC feature gets severely degraded when speech signal is corrupted with narrow-band channel noise, though few filter bank outputs may remain unaffected. In this work, we have studied a class of linear transformation techniques based on block wise transformation of MFLE which effectively decorrelate the filter bank log energies and also capture speech information in an efficient manner. A thorough study has been carried out on the block based transformation approach by investigating a new partitioning technique that highlights associated advantages. This article also reports a novel feature extraction scheme which captures complementary information to wide band information; that otherwise remains undetected by standard MFCC and proposed block transform (BT) techniques. The proposed features are evaluated on NIST SRE databases using Gaussian mixture model-universal background model (GMM-UBM) based speaker recognition system. We have obtained significant performance improvement over baseline features for both matched and mismatched condition, also for standard and narrow-band noises. The proposed method achieves significant performance improvement in presence of narrow-band noise when clubbed with missing feature theory based score computation scheme.}
}

@misc{Deruty_2022, title={Intuitive understanding of mfccs}, url={https://medium.com/@derutycsl/intuitive-understanding-of-mfccs-836d36a1f779}, journal={Medium}, publisher={Medium}, author={Deruty, Emmanuel}, year={2022}, month={Dec}} 

@misc{Kiran_2021, title={MFCC technique for speech recognition}, url={https://www.analyticsvidhya.com/blog/2021/06/mfcc-technique-for-speech-recognition/}, journal={Analytics Vidhya}, author={Kiran, Uday}, year={2021}, month={Jun}} 

@misc{Nakagawa_Wang, url={https://www.researchgate.net/publication/220656277_Speaker_Identification_and_Verification_by_Combining_MFCC_and_Phase_Information}, journal={Speaker identification and verification by combining MFCC and phase ...}, author={Nakagawa, Seiji and  Wang, Longbiao}}

@misc{Wu, url={https://www.atlantis-press.com/article/25875506.pdf}, journal={Music instrument classification using nontonal MFCC - Atlantis Press}, author={Wu, Y}} 

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@book{chapelle2006ssl,
  title={Semi-supervised learning},
  author={Chapelle, Olivier and Schölkopf, Bernhard and Zien, Alexander},
  year={2006},
  publisher={MIT Press}
}

@article{DADA2019e01802,
title = {Machine learning for email spam filtering: review, approaches and open research problems},
journal = {Heliyon},
volume = {5},
number = {6},
pages = {e01802},
year = {2019},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2019.e01802},
url = {https://www.sciencedirect.com/science/article/pii/S2405844018353404},
author = {Emmanuel Gbenga Dada and Joseph Stephen Bassi and Haruna Chiroma and Shafi'i Muhammad Abdulhamid and Adebayo Olusola Adetunmbi and Opeyemi Emmanuel Ajibuwa},
keywords = {Computer science, Computer security, Computer privacy, Analysis of algorithms, Machine learning, Spam filtering, Deep learning, Neural networks, Support vector machines, Naïve Bayes},
abstract = {The upsurge in the volume of unwanted emails called spam has created an intense need for the development of more dependable and robust antispam filters. Machine learning methods of recent are being used to successfully detect and filter spam emails. We present a systematic review of some of the popular machine learning based email spam filtering approaches. Our review covers survey of the important concepts, attempts, efficiency, and the research trend in spam filtering. The preliminary discussion in the study background examines the applications of machine learning techniques to the email spam filtering process of the leading internet service providers (ISPs) like Gmail, Yahoo and Outlook emails spam filters. Discussion on general email spam filtering process, and the various efforts by different researchers in combating spam through the use machine learning techniques was done. Our review compares the strengths and drawbacks of existing machine learning approaches and the open research problems in spam filtering. We recommended deep leaning and deep adversarial learning as the future techniques that can effectively handle the menace of spam emails.}
}

@inbook{AGGARWAL_2023, place={S.l.}, title={An Introduction to Neural Networks}, booktitle={Neural networks and deep learning: A textbook}, publisher={SPRINGER INTERNATIONAL PU}, author={AGGARWAL, CHARU}, year={2023}, pages={1–52}} 

@ARTICLE{9165253,
  author={Pelchat, Nikki and Gelowitz, Craig M.},
  journal={Canadian Journal of Electrical and Computer Engineering}, 
  title={Neural Network Music Genre Classification}, 
  year={2020},
  volume={43},
  number={3},
  pages={170-173},
  doi={10.1109/CJECE.2020.2970144}}

@misc{Nandi_2021, title={CNNs for Audio Classification}, url={https://towardsdatascience.com/cnns-for-audio-classification-6244954665ab}, journal={Medium}, publisher={Towards Data Science}, author={Nandi, Papia}, year={2021}, month={Dec}} 

@misc{Baheti, title={Activation functions in neural networks [12 types use cases]}, url={https://www.v7labs.com/blog/neural-networks-activation-functions}, journal={V7}, author={Baheti, Pragati}}

@misc{Gutpa_2022, title={Fundamentals of deep learning - activation functions and when to use them?}, url={https://www.analyticsvidhya.com/blog/2020/01/fundamentals-deep-learning-activation-functions-when-to-use-them/}, journal={Analytics Vidhya}, author={Gutpa, Dishashree}, year={2022}, month={Dec}} 

@misc{Ognjanovski_2020, title={Everything you need to know about neural networks and backpropagation machine learning made easy...}, url={https://towardsdatascience.com/everything-you-need-to-know-about-neural-networks-and-backpropagation-machine-learning-made-easy-e5285bc2be3a}, journal={Medium}, publisher={Towards Data Science}, author={Ognjanovski, Gavril}, year={2020}, month={Jun}} 

@misc{Wikilibros, title={Gráficos con TikZ}, url={https://es.wikibooks.org/wiki/Manual_de_LaTeX/Inclusi%C3%B3n_de_gr%C3%A1ficos/Gr%C3%A1ficos_con_TikZ}, journal={Wikilibros}} 

@misc{Rosebrock_2023, title={Convolutional Neural Networks (cnns) and layer types}, url={https://pyimagesearch.com/2021/05/14/convolutional-neural-networks-cnns-and-layer-types/}, journal={PyImageSearch}, author={Rosebrock, Adrian}, year={2023}, month={Jun}} 

@misc{Pramoditha_2022, title={Overview of a neural network’s learning process}, url={https://medium.com/data-science-365/overview-of-a-neural-networks-learning-process-61690a502fa}, journal={Medium}, publisher={Data Science 365}, author={Pramoditha, Rukshan}, year={2022}, month={Feb}} 

@misc{Koech_2022, title={Cross-entropy loss function}, url={https://towardsdatascience.com/cross-entropy-loss-function-f38c4ec8643e}, journal={Medium}, publisher={Towards Data Science}, author={Koech, Kiprono Elijah}, year={2022}, month={Jul}} 

@misc{Gartzman_2020, title={Getting to know the mel spectrogram}, url={https://towardsdatascience.com/getting-to-know-the-mel-spectrogram-31bca3e2d9d0}, journal={Medium}, publisher={Towards Data Science}, author={Gartzman, Dalya}, year={2020}, month={May}} 

@misc{Jordan_2018, title={Evaluating a machine learning model.}, url={https://www.jeremyjordan.me/evaluating-a-machine-learning-model/}, journal={Jeremy Jordan}, publisher={Jeremy Jordan}, author={Jordan, Jeremy}, year={2018}, month={Aug}} 

@misc{3.10_Documentation, title={Python 3.10 Documentation}, url={https://docs.python.org/3.10/}, journal={3.10 Documentation}}

@misc{librosa, title={Librosa documentation}, url={https://librosa.org/doc/latest/index.html}, journal={librosa}}

@misc{TensorFlow, title={TensorFlow - Documentation}, url={https://www.tensorflow.org/guide?hl=es-419}, journal={TensorFlow}}

@misc{scikit, title={Scikit-Learn - Documentation}, url={https://scikit-learn.org/stable/user_guide.html}, journal={scikit}}

@misc{Flask, title={Flask 2.3 - Documentation}, url={https://flask.palletsprojects.com/en/2.3.x/}, journal={Welcome to Flask - Flask Documentation (2.3.x)}} 

@misc{NumPy, title={NumPy v1.25 Manual}, url={https://numpy.org/doc/1.25/}, journal={NumPy documentation - NumPy v1.25 Manual}} 

@misc{pandas, title={Pandas 2.0.3 documentation}, url={https://pandas.pydata.org/docs/}, journal={pandas documentation - pandas 2.0.3 documentation}} 

@misc{matplotlib, title={Matplotlib Documentation}, url={https://matplotlib.org/stable/users/index.html}, journal={Users guide - Matplotlib 3.7.1 documentation}}

@misc{Microsoft_2021, title={Documentation for visual studio code}, url={https://code.visualstudio.com/docs}, journal={RSS}, publisher={Microsoft}, author={Microsoft}, year={2021}, month={Nov}}

@misc{Jupyter, title={Jupyter Documentation 4.1.1}, url={https://docs.jupyter.org/en/latest/}, journal={Project Jupyter Documentation - Jupyter Documentation 4.1.1 alpha documentation}} 

@misc{Team_2023, title={AI programming with Python: Integrating Machine Learning Into Your Business}, url={https://www.zartis.com/ai-programming-with-python/}, journal={Zartis}, author={Team, Zartis}, year={2023}, month={Apr}} 

@misc{Python3vsC, title={Python 3 vs C}, url={https://benchmarksgame-team.pages.debian.net/benchmarksgame/fastest/python3-gcc.html}, journal={Python 3 vs C gcc - Which programs are fastest?}} 

@misc{Loobuyck_2020, title={Scikit-learn, tensorflow, pytorch, keras... but where to begin?}, url={https://towardsdatascience.com/scikit-learn-tensorflow-pytorch-keras-but-where-to-begin-9b499e2547d0}, journal={Medium}, publisher={Towards Data Science}, author={Loobuyck, Ugo}, year={2020}, month={May}} 

@misc{Campbell_2023, title={Flask vs django – difference between them}, url={https://www.guru99.com/flask-vs-django.html}, journal={Guru99}, author={Campbell, Steve}, year={2023}, month={Jun}} 

@misc{scikit_tts, title={Scikit-Learn - Data Split}, url={https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html}, journal={scikit}} 

@article{article_cnn,
author = {Costa, Yandre and Soares de Oliveira, Luiz and Silla, Carlos},
year = {2017},
month = {01},
pages = {},
title = {An Evaluation of Convolutional Neural Networks for Music Classification Using Spectrograms},
volume = {52},
journal = {Applied Soft Computing},
doi = {10.1016/j.asoc.2016.12.024}
}

@misc{Scrum, title={What is Scrum?}, url={https://www.scrum.org/resources/what-scrum-module}, journal={Scrum.org}}

@misc{Andrada_2020, title={GTZAN dataset - music genre classification}, url={https://www.kaggle.com/datasets/andradaolteanu/gtzan-dataset-music-genre-classification}, journal={Kaggle}, author={Andrada}, year={2020}, month={Mar}}  

@INPROCEEDINGS{Bertin-Mahieux2011,
  author = {Thierry Bertin-Mahieux and Daniel P.W. Ellis and Brian Whitman and Paul Lamere},
  title = {The Million Song Dataset},
  booktitle = {{Proceedings of the 12th International Conference on Music Information
	Retrieval ({ISMIR} 2011)}},
  year = {2011},
  owner = {thierry},
  timestamp = {2010.03.07}
}

@misc{MSD, title={Million Song Dataset}, url={http://millionsongdataset.com/}, journal={Welcome! | Million Song Dataset}}

@misc{MagnaTagATune, title={The MagnaTagATune Dataset}, url={https://mirg.city.ac.uk/codeapps/the-magnatagatune-dataset}, journal={City University mirg}} 

@misc{Desai_2023, title={Web application vs Desktop Application: Pros and cons}, url={https://positiwise.com/blog/web-application-vs-desktop-application-pros-and-cons}, journal={POSITIWISE}, author={Desai, Jemin}, year={2023}, month={Jun}} 

@misc{PIERGALLINI_2023, title={Cómo mejorar Los Modelos de Aprendizaje Automático Con Técnicas de Aumento de Datos (data augmentation)}, url={https://franspg.dev/2020/01/27/generacion-de-datos-artificiales-data-augmentation/}, journal={Franco Piergallini Guida}, author={ PIERGALLINI, FRANCO}, year={2023}, month={Mar}} 

@misc{choi2020zeroshot,
      title={Zero-shot Learning for Audio-based Music Classification and Tagging}, 
      author={Jeong Choi and Jongpil Lee and Jiyoung Park and Juhan Nam},
      year={2020},
      eprint={1907.02670},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{10.1145/3184558.3191822,
author = {Murauer, Benjamin and Specht, G\"{u}nther},
title = {Detecting Music Genre Using Extreme Gradient Boosting},
year = {2018},
isbn = {9781450356404},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3184558.3191822},
doi = {10.1145/3184558.3191822},
abstract = {This paper summarizes our contribution to the CrowdAI music genre classification challenge "Learning to Recognise Musical Genre from Audio on the Web'' as part of the WebConference 2018. We utilize different approaches from the field of music analysis to predict the music genre of given mp3 music files, including a convolutional neural network for spectrogram classification, deep neural networks and ensemble methods using various numerical audio features. Our best results were obtained by an extreme gradient boosting classifier.},
booktitle = {Companion Proceedings of the The Web Conference 2018},
pages = {1923–1927},
numpages = {5},
keywords = {music classification, gradient boosting, neural network},
location = {Lyon, France},
series = {WWW '18}
}

@misc{Mu_Yin_Huang_Xu_Du_2021, title={Environmental sound classification using temporal-frequency attention based convolutional neural network}, url={https://www.nature.com/articles/s41598-021-01045-4}, journal={Nature News}, publisher={Nature Publishing Group}, author={Mu, Wenjie and Yin, Bo and Huang, Xianqing and Xu, Jiali and Du, Zehua}, year={2021}, month={Nov}} 

@misc{LLP, title={Host, run, and code python in the cloud!}, url={https://www.pythonanywhere.com/}, journal={PythonAnywhere}, author={LLP, PythonAnywhere}} 