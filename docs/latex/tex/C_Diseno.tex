\apendice{Especificación de diseño}

\section{Introducción}

En esta sección se define cómo se han implementado las especificaciones técnicas vistas en el apéndice B. En concreto 
cómo se han implementado las especificaciones técnicas y cómo se han estructurado los datos y los procedimientos. 
También se describirá la arquitectura general del sistema.

\section{Diseño de datos}

La aplicación maneja varios tipos de datos, que se describen a continuación:

\begin{itemize}
\tightlist

\item \textbf{Archivos CSV}: Los archivos CSV son utilizados para almacenar información sobre los metadatos de los archivos de audio \cite{CSV_documentation}.
En concreto, se trabaja con el fichero \texttt{tracks.csv} que contiene una gran cantidad de información sobre cada pista de audio y con el fichero \texttt{raw\textunderscore genres.csv} que contiene información sobre cada género musical.
Estos ficheros se procesan para generar el archivo \texttt{track\textunderscore genres.csv}, que contiene el identificador de la pista de audio y sus géneros, y es más sencillo para su uso a la hora de introducir las características y entrenar el modelo.

\item \textbf{Archivos de audio}: Los archivos de audio, en formato \texttt{.mp3} \cite{MP3}, son los datos de entrada principales en la aplicación. Estos son analizados y procesados para extraer las características necesarias para su predicción.

\item \textbf{Archivos pickle}: Se ha optado por el uso de este tipo de ficheros para almacenar el conjunto de datos de entrenamiento procesado, \texttt{track\textunderscore genres\textunderscore mfcc.pkl}, debido a que mantiene mejor la información de las características que un fichero CSV tradicional.
Este fichero se utiliza para entrenar el modelo de aprendizaje automático \cite{Selvaraj_2023}.

\end{itemize}

\section{Diseño procedimental}

\subsection{Procedimiento de funcionamiento básico}

El diseño procedimental de la aplicación sigue un flujo de trabajo definido de la siguiente forma:

\begin{enumerate}
\tightlist

\item \textbf{Carga de datos}: El usuario carga un fichero de audio que se desea clasificar.

\item \textbf{Procesamiento de audio}: La aplicación procesa el audio extrayendo características necesarias para su clasificación.

\item \textbf{Clasificación de audio}: El modelo de aprendizaje automático realiza la predicción del género musical del fichero de audio.

\item \textbf{Visualización del resultado}: La aplicación devuelve el resultado de las predicciones al usuario.

\end{enumerate}

\imagen{secuencia_procedimiento_funcionamiento_basico}{Funcionamiento básico de la aplicación - Diagrama de secuencia}

\subsection{Procedimiento de extracción de características de audio de un fichero}

\begin{enumerate}
\tightlist

\item \textbf{Carga de datos}: El archivo de audio es cargado por la aplicación.

\item \textbf{Procesamiento de audio}: Se realiza un procesado del archivo recortando su longitud.

\item \textbf{Extracción de características}: Mediante el uso de la biblioteca \texttt{librosa} se extraen las características MFCC del fichero de audio.

\item \textbf{Normalización de las características}: Las características extraídas se normalizan para que tengan el mismo peso en el entrenamiento o predicción.

\end{enumerate}

\imagen{secuencia_procedimiento_extraccion_caracteristicas}{Extracción de características de un fichero de audio - Diagrama de secuencia}

\subsection{Procedimiento de extracción de características de audio para los ficheros de entrenamiento}

\begin{enumerate}
\tightlist

\item \textbf{Carga de datos}: Se recorren de forma iterativa todos los ficheros de audio en la carpeta \texttt{/data/raw} y se realiza el proceso siguiente individualmente en cada fichero.

\item \textbf{Procesamiento de audio}: Se realiza un procesado de los archivos recortando su longitud.

\item \textbf{Extracción de características}: Mediante el uso de la biblioteca \texttt{librosa} se extraen las características MFCC de los ficheros de audio.

\item \textbf{Normalización de las características}: Las características extraídas se normalizan para que tengan el mismo peso en el entrenamiento o predicción.

\item \textbf{Salida en archivo}: Las características extraídas se guardan junto a sus géneros musicales en un archivo.

\end{enumerate}

\imagen{secuencia_procedimiento_extraccion_caracteristicas_entrenamiento}{Extracción de características de los datos de entrenamiento - Diagrama de secuencia}

\subsection{Procedimiento de entrenamiento del modelo}

\begin{enumerate}
\tightlist

\item \textbf{Carga de datos}: Los datos de entrenamiento (características MFCC y géneros musicales) son cargados en memoria.

\item \textbf{Partición de los datos}: Se divide el conjunto de datos en un conjunto de entrenamiento, test y validación.

\item \textbf{Creación del modelo}: Se crea una instancia de la red neuronal que se va a utilizar para realizar el entrenamiento.

\item \textbf{Compilación del modelo}: Se elige un optimizador, una función de pérdida y la métrica objetivo que se desea utilizar y se compila el modelo.

\item \textbf{Entrenamiento del modelo}: Se entrena y valida el modelo con los datos de entrenamiento y de validación.

\item \textbf{Guardado del modelo}: Una vez termina el proceso de entrenamiento se guarda el modelo en el sistema.

\end{enumerate}

\imagen{secuencia_procedimiento_entrenamiento}{Proceso de entrenamiento del modelo - Diagrama de secuencia}

\subsection{Visualización de características}

\begin{enumerate}
\tightlist

\item \textbf{Carga de datos}: El archivo de audio se carga en memoria.

\item \textbf{Extracción de características}: Mediante el uso de la biblioteca \texttt{librosa} se extraen las características principales del archivo de audio.

\item \textbf{Generación de gráficos}: Mediante el uso de la biblioteca de visualización \texttt{Matplotlib}, se generan gráficos que representan visualmente las características extraídas.

\item \textbf{Visualización de gráficos}: Los gráficos generados se envían al servidor web para que el usuario pueda visualizarlos.

\end{enumerate}

\imagen{secuencia_procedimiento_visualizacion}{Proceso de visualización de características - Diagrama de secuencia}

\section{Diseño arquitectónico}

El diseño arquitectónico de la aplicación sigue un modelo de capas \cite{Blancarte}.
El modelo de capas es un arquitectura de software en las que las responsabilidades del software se dividen en capas apiladas. Cada capa ofrece servicios a la capa superior y los recibe de la capa inferior.

\subsection{Capa de presentación}

La capa de presentación se ocupa de la interacción e interfaz de usuario. Utiliza la biblioteca \texttt{Flask} para funcionar y permite a los usuarios cargar archivos musicales, iniciar el proceso de predicción y visualizar los resultados finales.
Es en esta capa donde se renderizan los archivos HTML \cite{HTML_tutorial} y donde se realiza el intercambio de mensajes mediante el protocolo HTTP \cite{MozDevNet}. Esta capa está comunicada con la capa de lógica, que le devolverá la información para poder mostrar los resultados.

\subsection{Capa de lógica}

La capa de lógica o lógica de negocio es donde se produce el funcionamiento interno de la aplicación. El funcionamiento de la lógica de la aplicación funciona bajo el lenguaje de programación \texttt{Python} y varias bibliotecas. En concreto se ejecutan las siguientes funcionalidades:

\begin{itemize}
\tightlist

\item \textbf{Extracción de características de audio}

\item \textbf{Procesamiento de los datos de audio}

\item \textbf{Entrenamiento del modelo}

\end{itemize}

\subsection{Capa de acceso a datos}

Esta capa se ocupa del almacenamiento y recuperación de datos. Los datos con los que trabaja esta capa son: archivos de audio, archivos CSV, archivos de características, etc.

Esta capa se comunica con la capa de lógica, proporcionándole los datos necesarios para su funcionamiento y almacenando sus resultados.

\imagen{esquema-capas-datos}{Esquema con las capas de la aplicación.}

\section{Diseño de la interfaz}

La interfaz de usuario proporciona la interacción directa entre el usuario y el sistema. En la aplicación la interfaz de usuario está centrada en la facilidad de uso y la visualización de los resultados.

\subsection{Interfaz de usuario}

El diseño de la interfaz de usuario está construido utilizando el lenguaje de marcado \texttt{HTML}. \texttt{Flask} se utiliza para definir las solicitudes y las respuestas \texttt{HTTP} y que de este modo, el navegador pueda renderizar los archivos HTML que forman la interfaz de usuario. 
Las imágenes utilizadas en la interfaz de usuario se han obtenido de la plataforma \textit{Flaticon} \cite{Flaticon}, la fuente utilizada es \texttt{Poppins} y ha sido extraída de \textit{Google Fonts} \cite{Google_Fonts}.

Incluye los siguientes elementos:

\textbf{Pantalla de inicio}: La pantalla de inicio es lo primero que ve el usuario al iniciar la aplicación. Proporciona una breve introducción sobre el propósito y funcionamiento de la aplicación y permite cargar un archivo de audio para iniciar el proceso de predicción musical.

\imagen{inicio}{Pantalla de inicio de la aplicación.}

\textbf{Selección de modelos y reproducción de audio}: Esta sección permite al usuario ver información básica sobre la pista de audio subida, como la duración o la frecuencia de muestreo, y elegir qué modelo entrenado se va a utilizar para realizar la predicción musical.

\imagen{info_cancion}{Pantalla de selección de modelos y reproducción de audio.}

\textbf{Visualización de resultados}: Sección donde el usuario puede ver el resultado de la predicción y una serie de características sobre la pista de audio con una breve descripción de cada una. La presentación de la información es tanto en modo texto como con gráficas.

\imagen{waveform}{Pantalla de visualización de resultados.}