\capitulo{5}{Aspectos relevantes del desarrollo del proyecto}

\section{Desarrollo del Proyecto}

El desarrollo de este proyecto se ha llevado a cabo utilizando una metodología ágil basada en Scrum \cite{Scrum}. Este enfoque proporciona flexibilidad necesaria para adaptar cambios en los requerimientos y para mejorar iterativamente el proyecto durante su desarrollo.
Las metodología ágiles se basan en la idea de dividir el proyecto en ciclos iterativos llamados \textit{sprints}, donde se llevan a cabo actividades de planificación, desarrollo, pruebas y revisión. 
Estos sprints suelen tener una duración fija, en este caso han sido de 1 semana con alguna excepción justificada.

\subsection{Metodología Scrum}
En el documento \texttt{anexos} se explica en detalle el proceso de desarrollo del proyecto.

En resumen el desarrollo ha consistido en los siguientes pasos iterativos:

\begin{enumerate}
\item \textbf{Planificación inicial}: Etapa de definición de objetivos generales del proyecto. Creación del \textit{product backlog}.

\item \textbf{Reuniones de sprint}: Al comienzo de cada \textit{sprint}, se realiza una pequeña reunión para revisar las tareas realizadas y seleccionar las tareas a desarrollar.

\item \textbf{Desarrollo del sprint}: Durante el \textit{sprint}, se trabaja en cada una de las tareas asignadas.

\item \textbf{Mejora continua}: La metodología ágil promueve la mejora continua y el aprendizaje a lo largo del desarrollo del proyecto.
\end{enumerate}

\subsection{Datos de entrenamiento}

El objetivo del proyecto es aplicar técnicas de Inteligencia Artificial (IA) y Aprendizaje Automático (ML) para la clasificación de estilos musicales. 
Durante la fase de análisis, se estudiaron varios modelos de ML, eligiendo finalmente la Red Neuronal Convolucional (CNN) debido a su mayor eficacia \cite{article_cnn}.

Otro factor a tener en cuenta en un proyecto de IA es el conjunto de datos. Se han planteado diversos conjuntos de datos para entrenar el modelo como:
\begin{itemize}

\item \textbf{GTZAN Dataset}: conjunto de datos muy utilizado en la clasificación musical. Recopilado por George Tzanetakis en 2002, consta de \textbf{1000 fragmentos} de audio de \textbf{30 segundos}, distribuidos en \textbf{10 géneros musicales} \cite{Andrada_2020}.

\item \textbf{Million Song Dataset}: conjunto de datos formado por las \textit{características musicales y metadatos} de un millón de canciones populares. No incluye pistas de audio \cite{Bertin-Mahieux2011, MSD}.

\item \textbf{MagnaTagATune}: conjunto de datos formado por \textbf{25863 fragmentos} de audio de \textbf{29 segundos} \cite{MagnaTagATune}.

\item \textbf{FMA (Free Music Archive)}: conjunto de datos musicales, libre de derechos, constituido por \textbf{106574 fragmentos} de audio de \textbf{30 segundos}. \cite{defferrard2017fma}

\end{itemize}

Finalmente se ha elegido el conjunto de datos \textbf{FMA (Free Music Archive)} para realizar el entrenamiento del modelo. Esto es debido a que ofrece una gran cantidad de pistas musicales libres de derechos. Además, al incluir las pistas musicales (a diferencia de Million Song Dataset por ejemplo)
es posible extraer las características de forma manual utilizando librosa u otras herramientas.

\subsection{Diseño}

En cuanto al diseño de la aplicación, en un primer momento se pensó en el desarrollo de una aplicación de escritorio. Sin embargo, esta idea fue descartada y se optó por desarrollar una aplicación web debido a las siguientes razones \cite{Desai_2023}:

\begin{itemize}

\item \textbf{Evolución tecnológica}: Es una realidad que las aplicaciones web están dominando el momento tecnológico actual, por lo que realizar el proyecto en web es una buena manera de estar al día de esta tecnología.

\item \textbf{Accesibilidad}: La aplicación web es accesible desde cualquier dispositivo con una conexión a internet, independientemente del sistema operativo. De esta manera se amplía el alcance de la aplicación.

\item \textbf{Actualizaciones}: Cuando se actualiza una aplicación web, automáticamente los usuarios reciben la última versión disponible en producción, eliminando la necesidad de descargar e instalar actualizaciones manualmente. 

\item \textbf{Mantenimiento}: Generalmente es más sencillo mantener una aplicación web que una aplicación de escritorio, ya que factores como hardware o sistema operativo del usuario desaparecen.
\end{itemize}

El marco de trabajo escogido para realizar la implementación de la aplicación web ha sido:

\begin{itemize}

\item \textbf{\textit{Backend}}: Para el \textit{backend} se ha utilizado Flask, un framework web comptabile con Python, pensado para realizar aplicaciones web y APIs.

\item \textbf{\textit{Frontend}}: Para el \textit{frontend}, se ha optado por HTML y CSS. HTML es un lenguaje de marcado que define la estructura y contenidos de las páginas web que conforman la aplicación. CSS es utilizado para definir los estilos de los documentos HTML y añadir elementos atractivos para el usuario.

\end{itemize}

\newpage

\section{Extracción de características de audio}

En este sección se va a analizar el proceso de extracción de características de audio.

\subsection{Extracción de MFCC usando Python y librosa}

El método de extracción de MFCC está diseñado para recorrer todos los archivos en un directorio especificado y extraer las características MFCC de cada archivo de audio que encuentre. La explicación de los detalles relevantes es la siguiente:

\begin{enumerate}
\tightlist
\item \textbf{Carga de archivos}: Carga del archivo de audio, devolviendo tanto la señal de audio \texttt{y} como la frecuencia de muestreo \texttt{sr}.

\item \textbf{Duración estándar}: Se extraen los primeros 25 segundos de cada pista de audio para obtener la misma dimensionalidad en todo el conjunto de datos.

\item\textbf{Extracción de coeficientes MFCC}: Se extraen 10 coeficientes MFCC de cada pista de audio. Se ha decidido extraer 10 coeficientes ya que es un número válido en el caso de este problema para realizar la clasificación, además su dimensionalidad es correcta para hacer el entrenamiento eficiente.

\item \textbf{Normalización}: Los coeficientes MFCC extraídos se normalizan restando la media y dividiendo por la desviación estándar. Este proceso se llama \textit{Normalización Z-Score} y se calcula de la siguiente manera.

\begin{equation}
z = \frac{x - \mu}{\sigma}
\end{equation}

donde \(z\) es el valor estandarizado, \(x\) es el valor de los coeficientes MFCC, \(\mu\) es la media de los coeficientes MFCC y \(\sigma\) es la desviación estándar de los coeficientes MFCC.

\end{enumerate}

\subsection{Extracción del resto de características}

Para generar visualizaciones, se ha repetido el proceso de extracción de características con:

\begin{enumerate}
\tightlist
\item \textbf{Onda de audio}: Se genera convirtiendo el archivo de audio en una onda unidimensional. Esta onda se puede visualizar en un gráfico, de esta manera se puede ver de una forma sencilla las diferentes variaciones en el volumen de la pista de audio a lo largo del tiempo notando los cambios de ritmo o de estructura. Este proceso es realizado con \texttt{librosa}.

\item \textbf{Espectrograma}: Se genera cargando el archivo de audio y realizando el proceso visto en el apartado \texttt{3.3. Ejemplo teórico de extracción de características musicales} utilizando \texttt{librosa}.

\item \textbf{Cromagrama}: Se genera mediante \texttt{librosa}.
\end{enumerate}

\newpage

\section{Técnicas de aumento de datos}

Las técnicas de aumentación de datos se basan en la generación de datos artificiales por medio de modificaciones de los datos originales \cite{PIERGALLINI_2023}. Esta técnica es importante en conjuntos de datos con pocos ejemplos o cuyos ejemplos no son suficientes para realizar un entrenamiento de calidad.
En este proyecto se han planteado diversas técnicas de aumentación de datos, aunque finalmente no ha sido necesaria su incorporación. De todas maneras se ha considerado conveniente tener en cuenta todas estas técnicas para ahondar más profundamente en el estudio.

\begin{itemize}
\tightlist

\item \textbf{Adicción de ruido de fondo}: la adicción de ruido de fondo es una técnica utilizada en los clips de audio que consiste en añadir un sonido estático, como ruido blanco o ruido ambiental, de esta manera se puede ayudar al modelo a entender los diferentes sonidos de fondo.

\item \textbf{Cambio de tono (\textit{pitch shifting})}: esta técnica consiste en variar la tonalidad o la frecuencia de la pista de audio sin cambiar su velocidad, de esta manera el modelo es capaz de generalizar mejor en situaciones donde hay diferentes tonalidades.

\item \textbf{Estiramiento temporal (\textit{time stretching})}: esta técnica, a diferencia del \textit{pitch shifting}, consiste en variar la velocidad del audio sin cambiar su tono o frecuencia. Esto ayuda al modelo a entender diferentes velocidades en el habla o en los instrumentos.

\item \textbf{Efectos auditivos}: se añaden efectos a la pista de audio como pueden ser eco, reverberación o chorus. De esta manera el modelo aprende a ser más robusto en estas situaciones.

\end{itemize}

\newpage

\section{Modelo de aprendizaje automático}

En esta sección se va a explicar en detalle las diferentes características del modelo de aprendizaje automático que se ha utilizado en el proyecto.

El modelo de aprendizaje automático utilizado es una representación de datos musicales procesados y algoritmos utilizados para realizar tareas de predicción de una clase.

\subsection{Procesamiento de datos}

Los datos con los que se alimentan al modelo utilizado son un conjunto de características musicales, en concreto 10 coeficientes MFCC, junto a su etiqueta correspondiente, el género musical. Con esta información el modelo aplicará algoritmos de machine learning para aprender de los datos y devolver nuevas predicciones
(generalizar) sobre datos nuevos o externos.

Los datos proceden de una gran cantidad de ficheros de audio, los cuales han sido procesados para extraer sus características más importantes. Una vez realizado este proceso, los datos procesados se guardan en un archivo, el cual será encargado de alimentar el modelo de aprendizaje automático.

Al realizar el procedimiento, se ha detectado un problema con la cantidad de datos a procesar. Los datos deben ser almacenados mientras se introducen al modelo, esto puede suponer un problema si se cuenta con un equipo no demasiado potente que no puede almacenar todos los datos en la memoria. 
En este caso se ha producido un problema de memoria a la hora de procesar el conjunto de datos \texttt{fma\textunderscore large} ya que su tamaño, una vez procesado, superaba el límite de memoria. Para solucionar este problema se ha implementado una solución que se basa en el uso de datasets incrementales mediante generadores. De esta manera los datos se devuelven iterativamente y no es necesario que se almacenen juntos en memoria.

\subsection{Redes neuronales}

Las redes neuronales utilizadas para el entrenamiento consiste una serie de capas convolucionales que van transformando las entradas en representaciones cada vez más sencillas y abstractas hasta llegar a la capa final, una capa densa, que realiza la clasificación en las clases correspondientes.

INSERTAR IMAGEN DEL RESUMEN DEL MODELO E IMAGEN DEL RESUMEN DE LAS CAPAS.

\section{Evaluación del rendimiento del modelo}

\subsection{Entrenamiento}

INSERTAR IMÁGENES DEL PROCESO DE ENTRENAMIENTO DEL MODELO.

\subsection{Explotación}

Una vez que el modelo ha sido entrenado se prueba con el 30\% de datos restantes los cuales son datos que no se han tenido en cuenta en el proceso de entrenamiento. Este proceso proporciona una evaluación del rendimiento del modelo y da una ídea sobre como se comportará el modelo con datos que insertará el usuario en la aplicación.

INSERTAR IMÁGENES DEL PROCESO DE EVALUACIÓN CON LOS DATOS DE TEST.

Además se ha evaluado el comportamiento del modelo con diferentes métricas, vistas anteriormente en la sección \texttt{3.8. Evaluación del modelo}.

INSERTAR MÉTRICAS DE RENDIMIENTO.